{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd791ef3",
   "metadata": {},
   "source": [
    "# Pre-lecture hw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093682a8",
   "metadata": {},
   "source": [
    "dataset csv file link: https://www.tablab.app/datasets/sample/csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85893666",
   "metadata": {},
   "source": [
    "1. Import the data and confirm that the dataset has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fd5534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = titanic_data.isnull().sum()\n",
    "\n",
    "# Display the missing values per column\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c62eec",
   "metadata": {},
   "source": [
    "2.1 print out the numbers of columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ddca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {titanic_data.shape[0]}\")\n",
    "print(f\"Number of columns: {titanic_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88101130",
   "metadata": {},
   "source": [
    "2.2 definitions for the terms \"observations\" and \"variables\":\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb57ac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "observations: individual rows of the dataset. \n",
    "    each observation is a single record or instance of data.\n",
    "    Within the Titanic dataset, the observation/ row represents one passeger which has all their information like their name, age, fare and survival status.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691e173",
   "metadata": {},
   "source": [
    "variables: individual columns of the dataset.\n",
    "    each variable is a characteristic measured or recorded for each observation. \n",
    "    Within the dataset, the variable/ column includes characteristics such as age, sex, fare, pclass, and survived for each passenger.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc2d764",
   "metadata": {},
   "source": [
    "3 summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8079f240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary of the Dataset:\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n",
      "\n",
      "General Information about the Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "Value counts for 'survived':\n",
      "survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for 'pclass':\n",
      "pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for 'sibsp':\n",
      "sibsp\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value counts for 'parch':\n",
      "parch\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Provide a statistical summary of the numerical and categorical columns\n",
    "print(\"Statistical Summary of the Dataset:\")\n",
    "print(titanic_data.describe(include='all'))\n",
    "\n",
    "# Overview of the dataset, including column types and missing values\n",
    "print(\"\\nGeneral Information about the Dataset:\")\n",
    "print(titanic_data.info())\n",
    "\n",
    "# Apply .value_counts() to numerical columns\n",
    "numerical_columns = ['survived', 'pclass', 'sibsp', 'parch']\n",
    "\n",
    "# Loop through each numerical column and print the value counts\n",
    "for col in numerical_columns:\n",
    "    print(f\"Value counts for '{col}':\")\n",
    "    print(titanic_data[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4cae2c",
   "metadata": {},
   "source": [
    "### 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b3005",
   "metadata": {},
   "source": [
    "df.shape gave the number of columns and rows.\n",
    "df.describe() gave the summeries of only the numerical columns (int and floats), showing like survived, pclass, age, sibsp, parch and fare. \n",
    "df.describe(include='all') gave all the variables, both the numerical and non-numerical(object and booleans). adding in sex, class, who, adult_male, deck,  embark_town, alive and alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c1ea1",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf52384",
   "metadata": {},
   "source": [
    "Attributes are characteristics of an object. They aren't function, they don't have parentheses (). df.shape is an attribute of a DataFrame, it returns a value, the dimensions of the DataFrame by its number of rows and columns.\n",
    "\n",
    "Methods are functions defined with the object class and data of the object. it can use parameters as it is a function. it can also perform action or calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a8cec",
   "metadata": {},
   "source": [
    "## chatgpt summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324bb48",
   "metadata": {},
   "source": [
    "### Summary of Our Conversation\n",
    "\n",
    "1. **Accessing the Titanic Dataset:**\n",
    "   - To load the Titanic dataset from a URL, you can use:\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "     titanic_data = pd.read_csv(url)\n",
    "     print(titanic_data.head())\n",
    "     ```\n",
    "\n",
    "2. **Checking for Missing Values:**\n",
    "   - To check for missing values in the dataset:\n",
    "     ```python\n",
    "     missing_values = titanic_data.isnull().sum()\n",
    "     print(missing_values)\n",
    "     ```\n",
    "\n",
    "3. **Number of Rows and Columns:**\n",
    "   - To print the number of rows and columns:\n",
    "     ```python\n",
    "     print(f\"Number of rows: {titanic_data.shape[0]}\")\n",
    "     print(f\"Number of columns: {titanic_data.shape[1]}\")\n",
    "     ```\n",
    "\n",
    "4. **Definitions:**\n",
    "   - **Observations:** Individual data entries or records (rows). In the Titanic dataset, each observation represents one passenger.\n",
    "   - **Variables:** Attributes or features that describe each observation (columns). In the Titanic dataset, variables include age, sex, fare, etc.\n",
    "\n",
    "5. **Summarizing Columns:**\n",
    "   - To provide statistical summaries of columns:\n",
    "     ```python\n",
    "     print(titanic_data.describe(include='all'))\n",
    "     print(titanic_data.info())\n",
    "     ```\n",
    "\n",
    "6. **Using `.value_counts()`:**\n",
    "   - To get counts of unique values for numerical variables:\n",
    "     ```python\n",
    "     numerical_columns = ['survived', 'pclass', 'sibsp', 'parch']\n",
    "     for col in numerical_columns:\n",
    "         print(f\"Value counts for '{col}':\")\n",
    "         print(titanic_data[col].value_counts())\n",
    "     ```\n",
    "\n",
    "7. **Discrepancies in Summary Statistics:**\n",
    "   - **Non-numeric Variables:** `df.describe()` by default only includes numeric columns unless `include='all'` is specified.\n",
    "   - **Missing Values:** The count in `df.describe()` for each column shows non-null values, which may be less than the total number of rows in the dataset due to missing values.\n",
    "\n",
    "**Definitions:**\n",
    "- **Attribute:** Characteristics or properties of an object, like `df.shape`, which does not use parentheses.\n",
    "- **Method:** Functions associated with an object, like `df.describe()`, which uses parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99860337",
   "metadata": {},
   "source": [
    "### chatgpt links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b382733d",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/721404cf-71d1-4f2d-85ca-24e99449041a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c2fa0",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/870fefda-8075-4a48-8d9c-ad2404545820"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24299efd",
   "metadata": {},
   "source": [
    "# post-lecture hw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e90ad",
   "metadata": {},
   "source": [
    "## 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80e9c2",
   "metadata": {},
   "source": [
    "count: The number of non-null observations in the dataset for each column. number of valid data points that are present.\n",
    "\n",
    "mean: The average value of the data points for each column. The sum of all values divided by the number of observations.\n",
    "\n",
    "std: The standard deviation of the values for each column. It measures the dispersion or spread of the data points around the mean. \n",
    "\n",
    "min: The minimum value in the dataset for each column. It represents the lowest observation in the dataset.\n",
    "\n",
    "25%: The 25th percentile of the data. This value divides the lowest 25% of the data from the rest.\n",
    "\n",
    "50%: The 50th percentile of the data. This value divides the data into two equal halves.\n",
    "\n",
    "75%: The 75th percentile of the data. This value divides the lowest 75% of the data from the top 25%.\n",
    "\n",
    "max: The maximum value in the dataset for each column. It represents the highest observation in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf36fc",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98b85e",
   "metadata": {},
   "source": [
    "### 7.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274bc64b",
   "metadata": {},
   "source": [
    "df.dropna() is preferred over del df['col'] is when there's missing data scattered across seeral rows but the rest \n",
    "of the column contains valuable information that should be kept. for example, in the titantic dataset,it’s more efficient to use df.dropna() to remove those specific rows rather than eliminating entire columns. dropping rows with missing values retains important features like age, fare, and embarkation point for analysis.Using del df['col'] would drop an entire column, which is unnecessary if the column has only a few missing values, potentially losing useful information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dab304",
   "metadata": {},
   "source": [
    "### 7.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd9392",
   "metadata": {},
   "source": [
    "If a column has a large percentage of missing values, like the Cabin column in the Titanic dataset, it's better to drop the column using del df['Cabin']. This preserves the rows and prevents losing important information from other columns. Using df.dropna() would remove rows with missing values, potentially losing a significant portion of the dataset. If the column isn’t critical, dropping it entirely is a more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a427923",
   "metadata": {},
   "source": [
    "### 7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15baa066",
   "metadata": {},
   "source": [
    "Applying del df['col'] before df.dropna() helps preserve valuable rows by removing columns with \n",
    "excessive missing data first, reducing the overall amount of missing values.\n",
    "\n",
    "Reduce Missing Data: Dropping columns with a high percentage of missing values (e.g., Cabin) \n",
    "first prevents df.dropna() from unnecessarily removing rows that are useful for other columns.\n",
    "\n",
    "Preserve Important Data: Removing unhelpful columns before dropping rows ensures that df.dropna() \n",
    "only affects rows with missing data in critical columns (like Age or Fare).\n",
    "\n",
    "Efficient Cleaning: This approach maximizes the retention of relevant data while simplifying the \n",
    "dataset for better analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fb1d4",
   "metadata": {},
   "source": [
    "chat link: https://chatgpt.com/share/fa41d89f-eddd-4f99-b47c-e5c328c005b8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5263c",
   "metadata": {},
   "source": [
    "### 7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee89215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            177\n",
      "embarked         2\n",
      "deck           688\n",
      "embark_town      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "#checking for missing values\n",
    "df = pd.read_csv(url)  # Example path to the Titanic dataset\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = df.isna().sum()\n",
    "print(missing_data[missing_data > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c597fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose 'deck' has too many missing values, \n",
    "del df['deck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe4635",
   "metadata": {},
   "source": [
    "Removing columns with too many missing values as it doesn't provide crucial information for the analysis or model. Since over 50% of the column is missing, it is better to remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "537b3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values before cleaning:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check for missing values after cleaning\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df_cleaned.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536396c2",
   "metadata": {},
   "source": [
    "Removing rows with missing values when the proportion of missing data in rows is low and doesn't significantly reduce the dataset size. the number of missing values is relatively small compared to the size of the dataset, and dropping these rows won't lead to significant information loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a368f",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8c003",
   "metadata": {},
   "source": [
    "### 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18c4bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "class                                                            \n",
       "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age'\n",
    "df.groupby(\"class\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9701ba78",
   "metadata": {},
   "source": [
    "This groups the data by the passenger class (\"class\") and provides descriptive statistics for the \"age\" column for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443786b",
   "metadata": {},
   "source": [
    "### 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c733be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc50ac3",
   "metadata": {},
   "source": [
    "comparing df.describe and df.groupby(\"class\")[\"age\"].describe(). the count for describe is much higher as it is counting for the whole dataset for how many non-missing (non-null) values there are. the count for the groupby is counting how many non-missing values of col2 (which is age) exist within each group of col1 (class). each value in col1 creates a group, and within col2's group's non-missing values are counted. \n",
    "\n",
    "\n",
    "\n",
    "Fundamental Difference:\n",
    "\n",
    "df.describe(): Counts per column across the whole dataset, regardless of grouping.\n",
    "\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): Counts per group for a specific column. This is influenced not just by missing values in col2, but also by how many rows belong to each group of col1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25041a",
   "metadata": {},
   "source": [
    "Here's a summary of our interaction:\n",
    "\n",
    "1. **Understanding `df.groupby(\"col1\")[\"col2\"].describe()`**:\n",
    "   - We discussed that `df.groupby(\"col1\")[\"col2\"].describe()` groups the data by `col1` and provides summary statistics for `col2` within each group.\n",
    "   - An example using the Titanic dataset was provided, where we grouped by passenger class (`class`) and described the age (`age`) distribution, showing statistics like mean, count, standard deviation, etc.\n",
    "\n",
    "2. **Renaming Columns**:\n",
    "   - Upon request, I demonstrated how to rename columns from `Pclass` to `class` and `Age` to `age` in the Titanic dataset, then performed the same `groupby` operation on the renamed columns.\n",
    "\n",
    "3. **Explaining Count Differences**:\n",
    "   - We explored the difference between the `count` value in `df.describe()` and `df.groupby(\"col1\")[\"col2\"].describe()`.\n",
    "     - **`df.describe()`** provides the count of non-missing values for each column across the entire dataset.\n",
    "     - **`df.groupby(\"col1\")[\"col2\"].describe()`** gives the count of non-missing values for `col2` within each group defined by `col1`.\n",
    "   - This highlights that `df.describe()` reflects the overall data, while the `groupby` approach breaks the count down by group (in our case, passenger class).\n",
    "\n",
    "This explanation helped clarify how missing data can affect these counts differently depending on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a4037",
   "metadata": {},
   "source": [
    "### 8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc863c5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# A: not importing pandas as pd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Group by 'class' and describe 'age'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# A: not importing pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age'\n",
    "df.groupby(\"class\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ef473",
   "metadata": {},
   "source": [
    "after removing the comment about not importing pandas, chat was able to figure it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4148f8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# B: Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dacfc",
   "metadata": {},
   "source": [
    "chat found the typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf3f8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "class                                                            \n",
       "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c: Try to use a dataframe before it's been assigned into the variable\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.groupby(\"class\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c9b91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "DF.groupby(\"class\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a2a08",
   "metadata": {},
   "source": [
    "chat figured out to change DF to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9b26d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1179552649.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    pd.read_csv(url`\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# D: Forget one of the parentheses somewhere the code\n",
    "\n",
    "pd.read_csv(url`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c46342",
   "metadata": {},
   "source": [
    "chat was able to know the missing bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d94d4ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_88/2138813385.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# E: Mistype one of the names of the chained functions with the code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "# E: Mistype one of the names of the chained functions with the code\n",
    "df.group_by(\"class\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa89f3",
   "metadata": {},
   "source": [
    "chat was able to take out the underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9acf2fc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# F: Use a column name that's not in your data for the groupby and column selection\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtitanic_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'titanic_df' is not defined"
     ]
    }
   ],
   "source": [
    "# F: Use a column name that's not in your data for the groupby and column selection\n",
    "\n",
    "titanic_df.groupby(\"Sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905762b",
   "metadata": {},
   "source": [
    "chat was able to change the capitalised letter to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33e41929",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# G: Forget to put the column name as a string in quotes for the groupby and column selection\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtitanic_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(Sex)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'titanic_df' is not defined"
     ]
    }
   ],
   "source": [
    "# G: Forget to put the column name as a string in quotes for the groupby and column selection\n",
    "\n",
    "titanic_df.groupby(Sex)[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2cc0f9",
   "metadata": {},
   "source": [
    "chat was able to add the quotations to \"sex\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621841a8",
   "metadata": {},
   "source": [
    "Certainly! Here's a summary of our interaction:\n",
    "\n",
    "1. **Initial Issue with `pd`**: You encountered a `NameError` because `pandas` was not imported. The solution was to add `import pandas as pd` to your code.\n",
    "\n",
    "2. **HTTPError**: You faced an `HTTPError` due to an incorrect URL. The solution was to use the correct URL for the Titanic dataset.\n",
    "\n",
    "3. **SyntaxError**: You had a `SyntaxError` caused by an extraneous backtick character. The solution was to remove the backtick and ensure correct syntax.\n",
    "\n",
    "4. **AttributeError**: You saw an `AttributeError` because you used `group_by` instead of `groupby`. The solution was to use the correct method name `groupby`.\n",
    "\n",
    "5. **NameError for DataFrame Variable**: You encountered a `NameError` because the DataFrame variable `titanic_df` was not defined. You should use the correct variable name, such as `df`, and ensure that column names are in quotes.\n",
    "\n",
    "6. **Final Correction**: The final recommendation was to use `df` (or your correctly defined DataFrame variable) and the correct column names (e.g., `\"sex\"` instead of `Sex`) in your code.\n",
    "\n",
    "Feel free to ask if you have more questions or need further assistance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd85c8",
   "metadata": {},
   "source": [
    "chat link: https://chatgpt.com/share/b6f68cff-d701-42e4-88a4-93b431b34b87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4420c48",
   "metadata": {},
   "source": [
    "### 3B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd403e",
   "metadata": {},
   "source": [
    "using google meant more reading and understanding the material. with chatgpt, it gave me the code to copy and paste back and it worked, meaning that i didn't really learn or did any actually coding or understanding of the code. both were similar in speed and the time spent on troubleshooting. \n",
    "\n",
    "to be honest, i used the same account to ask about the code, so chat might be able to compare the already correct and used code from our previous chats about the same dataset, so that would be why chat was all correct when i was fake trouble shooting. unlike google that has everything but no memory of what i have done or have in my code. I think that using google would be better if i dont have any previous coding experience but chat having memory of my this specific code for this dataset was the reason why it was better at troubleshooting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5dd476",
   "metadata": {},
   "source": [
    "# 9 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb0941",
   "metadata": {},
   "source": [
    "I couldn't figure out the wiki textbook, so no. but i use chat and read most of the posts on piazza when i needed some help. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
